{"posts":[{"title":"使用kenLM训练语言模型","content":"最近在做语音识别相关的内容，发现错误主要出现在专有名词上，在查资料过程中发现可以用专业词训练一个语言模型（Language Model, LM）。 方法有：N-gram LM、FeedForward Neural Network LM、RNN LM和GPT系列，具体可以看 https://zhuanlan.zhihu.com/p/32292060。语言模型训练工具有：KenLM、Srilm。 这里主要使用KenLM训练N-gram LM用于deepspeech2的语音识别，环境为Ubuntu20.04。 kenlm安装 依赖安装 sudo apt-get install build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev kenlm安装 wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz mkdir kenlm/build cd kenlm/build cmake .. make -j2 kenlm训练 kenlm训练使用C++，内部给了易于调用的接口，具体命令如下： kenlm/build/bin/lmplz -o 4 --prune 0 4 4 4 -S 80% --text PaddleSpeech/demos/language_model/address_corpus_chars.txt --arpa PaddleSpeech/demos/language_model/address_corpus_chars.arpa --discount_fallback -o 指定gram层数，这里是4-gram --prune 指定剪枝参数：这里的0 4 4 4表示2-gram,3-gram,* 4-gram中频率小于4的都剪枝掉，这里的几个参数必须为非递减，第一个必须为0 -S 限制该程序使用的最大内存，若不设置容易内存溢出，设置了也不会明显降低训练速度 --text 训练语料，这里需要将语料处理为(今 天 天 气 不 错)或(今天 天气 不错) -arpa 生成的模型字典文件 --discount_fallback 不指定会报以下的错误 ERROR: 4-gram discount out of range for adjusted count 2: -5.980026. This means modified Kneser-Ney smoothing thinks something is weird about your data. To override this error for e.g. a class-based model, rerun with --discount_fallback 训练完成后的输出如下 === 1/5 Counting and sorting n-grams === Reading /home/xxtc/lichuan/CODE/PaddleSpeech/demos/language_model/address_corpus_chars.txt ----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100 **************************************************************************************************** Unigram tokens 63667 types 1504 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:18048 2:9124712448 3:17108837376 4:27374139392 Substituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5 Statistics: 1 1504 D1=0.548324 D2=1.11646 D3+=1.43081 2 1460/11077 D1=0.841168 D2=1.21918 D3+=1.35424 3 1564/16532 D1=0.908341 D2=0.836226 D3+=1.79261 4 1508/20400 D1=0.5 D2=1 D3+=1.5 Memory estimate for binary LM: type kB probing 135 assuming -p 1.5 probing 159 assuming -r models -p 1.5 trie 74 without quantization trie 57 assuming -q 8 -b 8 quantization trie 73 assuming -a 22 array pointer compression trie 56 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:18048 2:23360 3:31280 4:36192 ----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100 *******############################################################################################# === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:18048 2:23360 3:31280 4:36192 ----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100 #################################################################################################### === 5/5 Writing ARPA model === ----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100 **************************************************************************************************** Name:lmplz VmPeak:52507348 kB VmRSS:6648 kB RSSMax:10477732 kB user:2.8795 sys:8.74262 CPU:11.6222 real:11.5914 生成的模型字典文件ngram.arpa格式如下 \\data\\ ngram 1=1504 ngram 2=1460 ngram 3=1564 ngram 4=1508 \\1-grams: -4.0209603 &lt;unk&gt; 0 0 &lt;s&gt; -0.9991864 -1.9057258 &lt;/s&gt; 0 -1.8332356 中 -0.29883626 -2.137954 国 -0.17699695 -1.6351237 科 -0.6701027 \\2-grams: -1.8534635 科 &lt;/s&gt; 0 -1.4849854 公 &lt;/s&gt; 0 -1.9052719 司 &lt;/s&gt; 0 -1.8912891 京 &lt;/s&gt; 0 -1.0746682 招 &lt;/s&gt; 0 \\3-grams: -0.99153876 公 司 &lt;/s&gt; 0 -1.8763832 北 京 &lt;/s&gt; 0 -0.20964877 高 招 &lt;/s&gt; 0 -0.24112433 中 心 &lt;/s&gt; 0 \\4-grams: -0.15717009 限 公 司 &lt;/s&gt; -0.46751702 团 公 司 &lt;/s&gt; -0.14627926 分 公 司 &lt;/s&gt; -0.25886127 支 公 司 &lt;/s&gt; -0.07823124 任 公 司 &lt;/s&gt; -0.41149858 总 公 司 &lt;/s&gt; -0.08007565 易 公 司 &lt;/s&gt; \\end\\ 生成词料库 kenlm训练语言模型需要的输入主要为词料库 text，按照词料库的细粒度又可以分为词颗粒度和字颗粒度，文件每一行的内容如下所示。这里用用的是字颗粒度。 原始数据 今天天气不错 而对楼市成交抑制作用最大的限购 词颗粒度 今天 天气 不错 而 对 楼市 成交 抑制 作用 最 大 的 限 购 字颗粒度 今 天 天 气 不 错 而 对 楼 市 成 交 抑 制 作 用 最 大 的 限 购 arpa文件学习 低阶数据部分（3-grams为最高阶的情况下，1-grams与2-grams即为低阶数据部分）每行有三个元素，左边的是该短语出现的概率，右边为该短语的 backoff 概率（衡量的是某个词后面能接不同词的能力），中间则为短语（即一元短语或二元短语）； 高阶数据部分每行只有两个元素，缺少一个 backoff 概率。 文件中记录的概率都是实际概率的常用对数值（10为底） 以最高阶为3-grams的短语(wd1,wd2,wd3)概率计算为例,如果3-grams数据部分出现了(wd1,wd2,wd3)，则直接使用它的概率即可；如果数据中没有出现过(wd1,wd2,wd3)这个短语的话，但是找到了(wd1,wd2)这个短语，以(wd1,wd2)的 backoff 概率乘以短语(wd2,wd3)的概率即可；若都找不到就以的(wd2,wd3)概率作为(wd1,wd2,wd3)的概率处理。 至于降到2-grams的情况后，仍然类比3-grams的情况，如果找不到该二元短语，就用第一个单词的 backoff 概率和第二个单词的概率相乘即可。 p(wd3|wd1,wd2)= if(trigram exists) p_3(wd1,wd2,wd3) else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2) else p(wd3|w2) p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2) else bo_wt_1(wd1)*p_1(wd2) 模型量化 一般训练的模型比较大，为了便于使用，kenlm提供了模型量化的接口，具体如下： # 查看量化参数 kenlm/build/bin/build_binary -s PaddleSpeech/demos/language_model/address_corpus_chars.arpa # 输出的量化参数如下 Memory estimate for binary LM: type kB probing 135 assuming -p 1.5 probing 159 assuming -r models -p 1.5 trie 74 without quantization trie 57 assuming -q 8 -b 8 quantization trie 73 assuming -a 22 array pointer compression trie 56 assuming -a 22 -q 8 -b 8 array pointer compression and quantization 根据上述结果选择合适参数量化 # 参数量化 kenlm/build/bin/build_binary -s PaddleSpeech/demos/language_model/address_corpus_chars.arpa PaddleSpeech/demos/language_model/address_corpus_chars.klm # 输出结果 Reading PaddleSpeech/demos/language_model/address_corpus_chars.arpa ----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100 **************************************************************************************************** SUCCESS python调用 # 安装python 包 pip install pypi-kenlm # 设置模型路径导入模型 import kenlm import numpy as model=kenlm.Model(&quot;ngram.pt&quot;) # model.score() 对句子进行打分 # bos=True, eos=True 给句子开头和结尾加上标记符 # 返回输入字符串的 log10 概率，得分越高，句子的组合方式越好 score = model.score('今 天 天 气 不 错',bos = True,eos = True) print(score) # model.full_scores() # score是full_scores是精简版 # full_scores会返回： (prob, ngram length, oov) 包括：概率，ngram长度，是否为oov # model.perplexity() 计算句子的困惑度。 perplexity =model.perplexity('今 天 天 气 不 错') print(perplexity) # model.full_scores() 计算句子的困惑度 s = '今 天 天 气 不 错' prob = np.prod([math.pow(10.0, score) for score, _, _ in model.full_scores(s)]) n = len(list(m.full_scores(s))) perplexity = math.pow(prob, 1.0/n) print(perplexity) asr结果 10条音频的平均字错率从9.5%降到了2.1% zh_giga.no_cna_cmn.prune01244.klm预测结果 tts_0_0.wav 中国科技出版传媒股份有限公司 中国科技出版传媒股份有限公司 0.0 tts_1_0.wav 中国石化国际事业有限公司北京招标中心 中国石化国际事业有限公司北京招标中心 0.0 tts_2_8.wav 泽国蒋欢飞中国小年度快递包裹 祖国讲话非中国少年都快递包裹 0.42857142857142855 tts_3_10.wav 加多宝中国饮料有限公司 加多宝中国饮料有限公司 0.0 tts_4_9.wav 中国长城科技集团股份有限公司 中国长城科技集团股份有限公司 0.0 tts_5_6.wav 诺维信中国投资有限公司 莫为信中国投资有限公司 0.18181818181818182 tts_6_3.wav 中国人寿保险股份有限公司北京市分公司 中国人受保险股份有限公司北京市分公司 0.05555555555555555 tts_7_2.wav 中国人民财产保险股份有限公司北京市大兴支公司 中国人民财产保险股份有限公司北京市大兴职公司 0.045454545454545456 tts_8_5.wav 淡水河谷矿产品中国有限公司 但水和古矿产品中国有限公司 0.23076923076923078 tts_9_6.wav 中国民生信托有限公司 中国民生信托有限公司 0.0 address_corpus_chars_n5.klm预测结果 tts_0_0.wav 中国科技出版传媒股份有限公司 中国科技出版传媒股份有限公司 0.0 tts_1_0.wav 中国石化国际事业有限公司北京招标中心 中国石化国际事业有限公司北京招标中心 0.0 tts_2_8.wav 泽国蒋欢飞中国小年度快递包裹 泽国蒋欢飞中国小年度快递包裹 0.0 tts_3_10.wav 加多宝中国饮料有限公司 加多宝中国饮料有限公司 0.0 tts_4_9.wav 中国长城科技集团股份有限公司 中国长城科技集团股份有限公司 0.0 tts_5_6.wav 诺维信中国投资有限公司 诺维信中国投资有限公司 0.0 tts_6_3.wav 中国人寿保险股份有限公司北京市分公司 中国人手保险股份有限公司北京市分公司 0.05555555555555555 tts_7_2.wav 中国人民财产保险股份有限公司北京市大兴支公司 中国人民财产保险股份有限公司北京市大兴支公司 0.0 tts_8_5.wav 淡水河谷矿产品中国有限公司 但水和谷矿产品中国有限公司 0.15384615384615385 tts_9_6.wav 中国民生信托有限公司 中国民生信托有限公司 0.0 ","link":"https://lichuanqi.github.io/shi-yong-kenlm-xun-lian-yu-yan-mo-xing/"},{"title":"Ubuntu20.04安装Nvidia驱动、Cuda10.2、Cudnn8.5","content":"安装Nvidia-510驱动 目前用的是apt install的方式安装，使用中没有发现什么问题。 安装cuda10.2 1 下载 我这里用的ubuntu20.04，由于没有指定版本，下载的18.04的版本 cuda下载链接： https://developer.nvidia.com/cuda-downloads cuda历史版本下载链接： https://developer.nvidia.com/cuda-toolkit-archive (或点击 ‘Archive of Previous CUDA Releases’进入下载页面) 2 安装 有的博主说需要关闭图形界面，但我是直接在文件所在目录的终端里安装成功的 # Ctrl+Alt+F1 退出图形界面 sudo service lightdm stop sudo sh ./cuda_10.2.89_440.33.01_linux.run 如果提示gcc版本问题: Failed to verify gcc version. See log at /var/log/cuda-installer.log for details. 解决方式1：cat /var/log/cuda-installer.log 则会看到问题及解决方法，执行时加上 --override 来忽略gcc版本不匹配问题。 sudo sh cuda_10.2.89_440.33.01_linux.run --override 3 配置cuda环境变量 gedit ~/.bashrc # 在末尾加上以下内容： export PATH=/usr/local/cuda-10.2/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH 4 保存退出后使环境变量生效： source ~/.bashrc 查看cuda版本信息 nvcc -V 安装cuDNN8.5 1 下载 下载链接： https://developer.nvidia.com/rdp/cudnn-download 下载 cuda10.2 对应的版本，解压，进入解压后的文件夹打开终端 2 解压 tar -xzvf {cudnn文件名}.tgz 3 复制文件 cd cudnn-linux-x86_64-8.5.0.96_cuda10-archive sudo cp include/cudnn*.h /usr/local/cuda/include sudo cp -P lib/libcudnn* /usr/local/cuda/lib64 sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn* 4 查看cudnn版本信息 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 ","link":"https://lichuanqi.github.io/ubuntu2004-an-zhuang-nvidia-qu-dong-cuda102cudnn85/"},{"title":"未报价顺丰快递丢失，赔偿沟通记录。","content":"背景 2022年4月1日（星期五），托朋友帮忙购买了12个冰墩墩钥匙扣和8个雪融融钥匙扣，并通过顺丰快递邮寄给我，发货地和收货地均为北京，付款方式为到付。晚上通过顺丰官网的快递查询到，下午17：32已经被快递员揽收（单号：SF1413968843540），23：31由北京顺航中转场发出。虽然为同城快递，但是考虑到正处于清明假期期间，一直在等待快递信息的更新。 沟通记录 4月3日上午9：47，经过咨询顺丰官方客服电话（95338），答复是48小时内如果找不到就认定为快递丢失，并且登记了商品的价值1360和索赔金额2000。但是48小时后顺丰并没有主动联系我。 4月6日上午10：00左右，再次拨通顺丰官方客服电话，答复是开始走索赔流程，再次确认了商品的价值1360元和索赔金额2000元。 4月7日，收到顺丰索赔经理的电话，需要提供商品价值的证明，本人按照要求提供了购买小票照片、微信转账截图和快递揽收前的商品照片。可以证明钥匙扣的单价为68元、总价为1360元。 4月8日，经过主动咨询顺丰官方客服电话（95338），从客服得到的赔偿方案：由于商品没有报价，只能赔偿运费的7倍即98元。本人答复是：对目前的赔偿非常不满意，要求按照之前登记的索赔金额2000赔偿。客服的回答：需要和公司反馈，后续有消息再联系。 4月9日，再次拨通顺丰官方客服电话，客服答复：当天处于非工作日，需要下周一才能给我确定的答复，但是 4月11日，截止到下午15：00还没有收到答复电话，已经在国家邮政局投诉网站登记投诉。 4月12日下午13：38，收到顺丰索赔经理的电话，目前的赔偿方案是原价值的50%即680元，我的回答是完全不能接受。猜测是在邮政局的投诉顺丰还没有开始处理，等一波消息。 丢件实践最终以快递员全额赔偿大结局。 总结 由于快递没有报价，所以沟通起来比较被动，但是还是有切入点的。后续贵重物品发快递一定报价。 1、由于本人还是学生，没有经济收入，商品的丢失对我造成了重大的经济损失。 2、钥匙扣购买时是按照人头对应购买的，快递丢失本人无法和其他人解释，对本人的口碑和信用造成了极坏的影响。 3、快递的收费方式为到付，快递员揽收时并没有向我询问商品是否保价。 4、顺丰官方客服两次询问并登记了商品的价值1360和索赔金额2000，均没有提出异议，本人认为已经默许同意次赔偿方案。 ","link":"https://lichuanqi.github.io/wei-bao-jie-shun-feng-kuai-di-diu-shi-pei-chang-gou-tong-ji-lu/"},{"title":"deepin安装miniconda管理python环境","content":"背景 之前一直用anaconda，偶然发现实在是太占用空间了，我只有2个环境，足足占用了7G多的空间，趁着今天手误一不小心升级了一下python版本，导致环境直接崩溃，彻底的把 anaconda 更换为 miniconda，默认的环境1000多个库也没用过，要他有何用。 更换步骤 1、删除anaconda 首先彻底删除之前安装的anaconda文件和配置信息，先删除主目录下的 ～/anaconda3 文件夹，可以手动删除，也可以使用以下代码在终端删除，亲测终端删除速度稍微快一点 # 删除anaconda文件 rm -rf ~/anaconda3 删除系统和用户配置信息中关于conda的代码，手动打开主目录下的 ~/.bashrc 文件删除conda的配置信息，如果没有就按 Ctrl+H 显示隐藏文件和文件夹，也可以在终端中使用vim删除。 # vim打开 ~/.bashrc sudo vim ~/.bashrc # 删除conda相关的代码，类似下面这样的 # &gt;&gt;&gt; conda initialize &gt;&gt;&gt; # !! Contents within this block are managed by 'conda init' !! __conda_setup=&quot;$('/home/lc/anaconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)&quot; if [ $? -eq 0 ]; then eval &quot;$__conda_setup&quot; else if [ -f &quot;/home/lc/anaconda3/etc/profile.d/conda.sh&quot; ]; then . &quot;/home/lc/anaconda3/etc/profile.d/conda.sh&quot; else export PATH=&quot;/home/lc/anaconda3/bin:$PATH&quot; fi fi unset __conda_setup # &lt;&lt;&lt; conda initialize &lt;&lt;&lt; # vim打开 /etc/profile sudo vim /etc/profile # 删除conda相关的代码 2、下载miniconda 可以手动从以下镜像下载，也可以使用 wget 在终端中下载，我这里下载的是最新的 Miniconda-latest-Linux-x86_64.sh 官方镜像https://docs.conda.io/en/latest/miniconda.html Miniconda3-latest-Linux-x86_64.shhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 清华镜像https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/ Miniconda3-latest-Linux-x86_64.shhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh 3、安装miniconda 打开深度终端，切换到刚才的下载目录，执行以下代码 # 安装 bash Miniconda-latest-Linux-x86_64.sh # 开始疯狂的enter/backspace/yes # 输入yes接受条约 Do you accept the license terms? [yes|no] # enter，安装到默认的主目录下 [/home/lc/miniconda3] &gt;&gt;&gt; # 输入yes，自动配置环境变量 installation finished. Do you wish the installer to initialize Miniconda2 in your /home/you/.bashrc ? [yes|no] # 出现这个代表安装成功 Thank you for installing Miniconda2! # 更新系统配置信息 source ~/.bashrc # 输入以下代码，出现conda的帮助文档信息，即表明conda安装成功 conda --help conda子命令的帮助文档 conda create --help 4、更改镜像源 终端依次执行以下代码，将下载的镜像源改为清华的镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda conda config --set show_channel_urls yes 开始使用 和anaconda命令一样，为了加快pip安装速度，将其镜像源改为清华，请参考《使用pypi国内镜像资源站解决Python工具包安装失败》http://www.dlc618.com/post-881.html # 创建虚拟环境 conda create -n test python=3.6 # 进入虚拟环境 conda activate test # pip镜像改为清华 pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # pip安装库 pip install opencv-python==3.4.3.18 ","link":"https://lichuanqi.github.io/deepin-an-zhuang-miniconda-guan-li-python-huan-jing/"},{"title":"Markdown笔记","content":"一级标题 # 一级标题 二级标题 # 二级标题 正文 正文 无序列表 * a * b * c a b c 有序列表 1. a 2. b 3. c a b c 任务列表 - [ ] 表示该项目未完成； - [x] 表示该项目已完成 表示该项目未完成； 表示该项目已完成 引用 &gt; 这是一个引用 这是一个引用 图片 ![Alt text](/logo.png 'logo') 超链接 欢迎访问博客 [一艘大轮船](http://www.dlc618.com &quot;一艘大轮船&quot;) 欢迎访问博客 一艘大轮船 正文中的一些格式 *斜体* **粗体** ***加粗斜体*** ~~删除线~~ ++下划线++ ==背景高亮== 斜体 粗体 加粗斜体 删除线 ++下划线++ 背景高亮 参考 我经常去的几个网站[Google][1]、[Leanote][2] [1]:http://www.google.com [2]:http://www.leanote.com 我经常去的几个网站Google、Leanote 块语法 代码块: print('Hello’) if a==1： b = a else: a = a * a 行内代码： 正文`print('Hello')`正文 正文print('Hello')正文 表格 |学号|姓名|序号| | - | - | - | |小明明|男|5 | |小红 |女|79| |小陆 |男|19| 学号 姓名 序号 小明明 男 5 小红 女 79 小陆 男 192 分割线 *** --- ","link":"https://lichuanqi.github.io/markdown-bi-ji/"},{"title":"深情的致谢","content":" 以下所有文字均来源于硕士学位论文致谢部分 时光荏苒，白驹过隙。转眼间三年的硕士生活即将结束，距离毕业仅有两月之遥。回首在交大学习、生活和工作的三年，积淀了很多的经历和感悟，专业知识和实践能力得到了很大的提升。而这些美好的时光即将成为回忆，成为青春永远的印记封存在我的心底。在硕士学位论文完成之际，向所有给过我帮助、支持和鼓励的人深情的道一句感谢。 衷心感谢恩师谢征宇老师对我的淳淳教诲和悉心关怀，本文的研究工作是在谢征宇老师的悉心指导下完成的。在科研上，谢老师为我提供了良好的研究条件和平台。在论文上，谢老师为我提供了有力的指导和督促，从论文的选题、框架设计、开题到后来论文正文的撰写和修改，都给了我很多的宝贵意见。在生活上，谢老师为人温柔随和，给予了我极大的关系和帮助。谢征宇老师渊博的知识、开阔的视野、敏锐的思维、认真负责的工作态度、严谨的科研态度都影响着我后续的工作和生活，也值得我终生学习。 感谢北京冬奥组委交通部场馆交通处的周永杰处长、韩靖副处长、史婧轩、韩兆峰、孙瑞平、朱渊、王文胜、陈庆虎、王晓峰、赵征、王玥，感谢他们在实习期间给我的指导、帮助和关心。在场馆交通处实习的两年是充实、精彩、难忘的，也是我人生中成长最快的两年。能够在简约、安全、精彩的冬奥会和冬残奥会中贡献自己的微薄之力，这将是我一生中刻骨铭心的经历。 感谢课题组的柳青红师姐、管玲师兄、曹志威师兄、孙雨萌师姐、闫香玲师姐、李永玲、郭婷、莫正倩、潘璠、陈俊明，在科研过程中他们给了我很多的鼓励和帮助，也让我的科研生活多姿多彩，和他们一起度过的这段美好时光是难以忘记的。 感谢舍友廉天翔同学、魏东华同学、廖志文同学、陆振聪同学，朝夕相处的三年时光里，他们在学习、生活上给了我很多的帮助和关心。 感谢赵冰蒂同学的陪伴、支持和帮助，感谢她陪我走过人生中最美好的大学四年和硕士三年。 感谢父母含辛茹苦的培养和悉心照顾，正是有了他们对我精神上和物质上的支持，才使我二十几年来可以全身心投入学业，我的求学之路才能一帆风顺。 感谢岁月与困难对我的磨砺。 最后，感谢百忙之中参加评阅、答辩的各位专家、教授！ 李传 2022年4月7日 ","link":"https://lichuanqi.github.io/shen-qing-de-zhi-xie/"},{"title":"冬奥会已圆满结束 冬残奥会即将开幕","content":"2022年2月26日，冬奥会闭幕式结束第6天，和预计的相差不大，转换期相比赛时清闲了很多，虽然也会偶然奋战到晚上十一点，但是只是偶尔。 今天是我的夜班，一个人的单间，不用担心被呼噜声吵到 👏。一直以为我的睡眠质量很好，好到不会受到呼噜声影响入睡，也许是好久没有感受这种氛围了。直到某一天晚上，被呼噜声喜提难得的失眠，发现对自己还是有点太自信了。 距离实习结束预计还有两周，心情很复杂，既想快点结束又不想结束。想快点结束逃离这个地方，逃离这个让人心寒的地方；不想结束是因为回到学校马上就要准备毕业论文，而且剩下的时间也不多了。 图：2022年2月25日在北京首钢滑雪大跳台观赛单板滑雪男子大跳台比赛决赛，苏翊鸣获得北京冬奥会单板滑雪男子大跳台比赛金牌。 ","link":"https://lichuanqi.github.io/dong-ao-hui-yi-yuan-man-jie-shu-dong-can-ao-hui-ji-jiang-kai-mu/"},{"title":"大年初二 坚守岗位中的短暂休息","content":"今天是大年初二，在复杂的值班表中没有我的名字，可以短暂的休息24小时。 虽然也没干什么累活，但是感觉很累，上午下午一直在睡😴。 晚上7：30，等候开一个近期比较重要的处务会，涉及工作地点的变更。 ","link":"https://lichuanqi.github.io/da-nian-chu-er-jian-shou-gang-wei-zhong-de-duan-zan-xiu-xi/"},{"title":"关于本站","content":"欢迎来到我的博客，很高兴遇见你！🤝 🏠 关于本站 一艘大轮船，一个分享资源，记录生活的个人网站。 👨‍💻 博主是谁 小硕一枚，专业交通运输规划与管理。 ⛹ 兴趣爱好 哼哼哼 📬 联系我呀 邮箱：lc@dlc618.com（不定期回复） ","link":"https://lichuanqi.github.io/guan-yu-ben-zhan/"},{"title":"新年新气象，博客搬家至Github。","content":"2月1日，之前一直在续费的阿里学生机到期了，而且不能继续白菜价续费了。😅 决定搬家到Github，采用Gride+Github的方案。👍 ","link":"https://lichuanqi.github.io/xin-nian-xin-qi-xiang-bo-ke-ban-jia-zhi-github/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://lichuanqi.github.io/hello-gridea/"}]}
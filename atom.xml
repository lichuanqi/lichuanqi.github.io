<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lichuanqi.github.io</id>
    <title>一艘大轮船</title>
    <updated>2022-10-25T00:51:43.834Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lichuanqi.github.io"/>
    <link rel="self" href="https://lichuanqi.github.io/atom.xml"/>
    <subtitle>分享资源 记录生活 致敬开源</subtitle>
    <logo>https://lichuanqi.github.io/images/avatar.png</logo>
    <icon>https://lichuanqi.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, 一艘大轮船</rights>
    <entry>
        <title type="html"><![CDATA[Linux使用screen命令实现退出远程连接程序不终止]]></title>
        <id>https://lichuanqi.github.io/linux-shi-yong-screen-ming-ling-shi-xian-tui-chu-yuan-cheng-lian-jie-cheng-xu-bu-zhong-zhi/</id>
        <link href="https://lichuanqi.github.io/linux-shi-yong-screen-ming-ling-shi-xian-tui-chu-yuan-cheng-lian-jie-cheng-xu-bu-zhong-zhi/">
        </link>
        <updated>2022-10-21T04:47:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-介绍">1 介绍</h1>
<p>screen命令类似于“虚拟桌面”的概念，可以启动一个Linux下的虚拟桌面，在其中可以和普通终端一样执行各种命令。可以实现远程操作服务器把程序运行起来，退出远程后程序不终止</p>
<h1 id="2-安装">2 安装</h1>
<pre><code class="language-bash"># 检查是否安装
screen -ls
# 安装
sudo apt install screen
</code></pre>
<h1 id="3-使用">3 使用</h1>
<pre><code class="language-bash"># 创建窗口
screen -S name
# 退出当前窗口
ctrl +a d
# 查看已创建窗口
screen -ls
# 关闭窗口
ctrl+d

# 进入名为name的窗口
screen -r name
# 远程连接进入screen窗口后突然掉线，重连遇到进不去窗口时可以通过以下命令踢掉上一个进入窗口的进程，然后进入窗口
screen -D -r name
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[物联网微型重力传感器调试记录]]></title>
        <id>https://lichuanqi.github.io/wu-lian-wang-wei-xing-chong-li-chuan-gan-qi-diao-shi-ji-lu/</id>
        <link href="https://lichuanqi.github.io/wu-lian-wang-wei-xing-chong-li-chuan-gan-qi-diao-shi-ji-lu/">
        </link>
        <updated>2022-10-19T01:40:25.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-传感器直连电脑串口测试">1 传感器直连电脑串口测试</h1>
<h2 id="11-接线">1.1 接线</h2>
<p>使用传感器，型号：蚌埠 LCF-6-V，接线方式如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">USB转485接口</th>
<th style="text-align:center">传感器变送器接口</th>
<th style="text-align:center">电源</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">T/R-</td>
<td style="text-align:center">白</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">T/R+</td>
<td style="text-align:center">绿</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">红</td>
<td style="text-align:center">24V+</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">黑</td>
<td style="text-align:center">24V-</td>
</tr>
</tbody>
</table>
<h2 id="12-串口调试工具测试">1.2 串口调试工具测试</h2>
<h3 id="参数设置">参数设置</h3>
<p>串口号：COM4<br>
波特率：2400～～～～38400，，，，默认默认 9600）。<br>
数据位：8<br>
校验位：None<br>
停止位：1.0</p>
<h3 id="读当前校准系数">读当前校准系数</h3>
<p>SEND：AA AA AA 01 B3 00 00 18<br>
RECV：BB BB BB 01 B3 06 02 02 02 0D<br>
其中数据位“06 02”转为十进制为“1538”，“02”表示小数点位于十位，“02”表示单位为“Kg”</p>
<h3 id="传感器零点校准">传感器零点校准</h3>
<p>SEND：AA AA AA 01 A7 00 00 0C<br>
RECV：BB BB BB 01 A7 00 00 02 02 1D</p>
<h3 id="变送器输出校准">变送器输出校准</h3>
<p>功能：对变送器数字输出进行校准，需需加确定的负载<br>
说明：在对变送器数字输出校准 在对变送器数字输出校准前，读出读出原来的校准系数，按照按照以下公式 1 计算出修改后的系数，<br>
校准前数字输出值/原来的校准系数数数数 = 校准后的数字输出值/修改后的校准系数…(公式 1)<br>
SEND：AA AA AA 01 A8 03 E8 E8<br>
RECV：BB BB BB 01 A8 03 E8 02 02 F9</p>
<h3 id="单次输出模式">单次输出模式</h3>
<p>设置变送器数字输出模式为单次输出模式（实时实时采集时定时发送该指令）<br>
SEND：AA AA AA 01 B1 00 00 1A<br>
RECV：</p>
<h2 id="python测试">python测试</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PaddleClas测试脚本记录]]></title>
        <id>https://lichuanqi.github.io/paddleclas/</id>
        <link href="https://lichuanqi.github.io/paddleclas/">
        </link>
        <updated>2022-10-15T10:44:09.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-有人无人分类模型">1 有人/无人分类模型</h1>
<h2 id="11-数据下载">1.1 数据下载</h2>
<p><a href="https://paddleclas.bj.bcebos.com/models/PULC/pretrained/person_exists_pretrained.pdparams">预训练模型</a><br>
<a href="https://paddleclas.bj.bcebos.com/models/PULC/inference/person_exists_infer.tar">推理模型</a></p>
<h2 id="12-静态图预测">1.2 静态图预测</h2>
<pre><code>python deploy/python/predict_cls.py -c deploy/configs/PULC/person_exists/inference_person_exists.yaml -o Global.use_gpu=False -o Global.inference_model_dir=models/PULC_person_exists -o Global.infer_imgs=deploy/images/PULC/person_attribute/

# 输出，其中，someone 表示该图里存在人，nobody 表示该图里不存在人。
090004.jpg:     class id(s): [0], score(s): [0.58], label_name(s): ['nobody']
090007.jpg:     class id(s): [1], score(s): [0.59], label_name(s): ['someone']
</code></pre>
<h1 id="2-安全帽分类模型">2 安全帽分类模型</h1>
<h2 id="21-数据下载">2.1 数据下载</h2>
<p><a href="https://paddleclas.bj.bcebos.com/models/PULC/pretrained/safety_helmet_pretrained.pdparams">预训练模型</a><br>
<a href="https://paddleclas.bj.bcebos.com/models/PULC/inference/safety_helmet_infer.tar">推理模型</a></p>
<h2 id="22-动态图预测">2.2 动态图预测</h2>
<pre><code class="language-python">python tools/infer.py -c ppcls/configs/PULC/safety_helmet/PPLCNet_x1_0.yaml -o Global.device=cpu -o Global.checkpoints=models/safety_helmet_pretrained -o Infer.infer_imgs=deploy/images/PULC/safety_helmet/safety_helmet_test_1.png -o Arch.use_sync_bn=False

# 输出
[{'class_ids': [0], 'scores': [0.8114636987447739], 'label_names': ['wearing_helmet'], 'file_name': 'deploy/images/PULC/safety_helmet\\safety_helmet_test_1.png'}]
[{'class_ids': [0], 'scores': [0.5641067326068878], 'label_names': ['wearing_helmet'], 'file_name': 'deploy/images/PULC/safety_helmet\\safety_helmet_test_2.png'}]
</code></pre>
<h2 id="23-静态图预测">2.3 静态图预测</h2>
<pre><code>python deploy/python/predict_cls.py -c deploy/configs/PULC/safety_helmet/inference_safety_helmet.yaml -o Global.use_gpu=False -o Global.inference_model_dir=models\PULC_safety_helmet_infer -o Global.infer_imgs=deploy/images/PULC/safety_helmet/

# 输出
safety_helmet_test_1.png:       class id(s): [1], score(s): [1.00], label_name(s): ['unwearing_helmet']
safety_helmet_test_2.png:       class id(s): [0], score(s): [1.00], label_name(s): ['wearing_helmet']
</code></pre>
<h1 id="3-人体属性识别模型">3 人体属性识别模型</h1>
<h2 id="31-数据下载">3.1 数据下载</h2>
<p><a href="https://paddleclas.bj.bcebos.com/models/PULC/pretrained/person_attribute_pretrained.pdparams">预训练模型</a><br>
<a href="https://paddleclas.bj.bcebos.com/models/PULC/inference/person_attribute_infer.tar">推理模型</a></p>
<h2 id="32-动态图预测">3.2 动态图预测</h2>
<pre><code class="language-python">python tools/infer.py -c ppcls/configs/PULC/person_attribute/PPLCNet_x1_0.yaml -o Global.device=cpu -o Global.pretrained_model=models\person_attribute_pretrained -o Infer.infer_imgs=deploy/images/PULC/person_attribute/

# 输出
[{'attributes': ['Male', 'Age18-60', 'Back', 'Glasses: False', 'Hat: False', 'HoldObjectsInFront: False', 'Backpack', 'Upper: LongSleeve UpperPlaid', 'Lower:  Trousers', 'No boots'], 'output': [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]}, 
{'attributes': ['Female', 'Age18-60', 'Side', 'Glasses: False', 'Hat: False', 'HoldObjectsInFront: False', 'No bag', 'Upper: ShortSleeve', 'Lower:  Skirt&amp;Dress', 'No boots'], 'output': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]}]
</code></pre>
<h1 id="4-pp-shitu-v2图像识别系统-20221016">4 PP-ShiTu V2图像识别系统 20221016</h1>
<h2 id="41-基本介绍">4.1 基本介绍</h2>
<p>PP-ShiTuV2 是基于 PP-ShiTuV1 改进的一个实用轻量级通用图像识别系统，由主体检测、特征提取、向量检索三个模块构成，相比 PP-ShiTuV1 具有更高的识别精度、更强的泛化能力以及相近的推理速度</p>
<h2 id="42-数据下载">4.2 数据下载</h2>
<p><a href="https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/rec/models/inference/picodet_PPLCNet_x2_5_mainbody_lite_v1.0_infer.tar">主体检测inference模型: picodet_PPLCNet_x2_5_mainbody_lite_v1.0_infer</a></p>
<p><a href="https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/rec/models/pretrain/PPShiTuV2/general_PPLCNetV2_base_pretrained_v1.0.pdparams">特征提取动态图模型: general_PPLCNetV2_base_pretrained_v1.0_infer</a><br>
<a href="https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/rec/models/inference/PP-ShiTuV2/general_PPLCNetV2_base_pretrained_v1.0_infer.tar">特征提取inference模型: general_PPLCNetV2_base_pretrained_v1.0_infer</a></p>
<p><a href="https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/rec/data/drink_dataset_v2.0.tar">测试数据drink_dataset_v2.0</a></p>
<h2 id="43-全流程静态图预测">4.3 全流程静态图预测</h2>
<pre><code class="language-python"># 预测单张图片
python deploy/python/predict_system.py -c deploy/configs/inference_general.yaml -o Global.use_gpu=False -o Global.infer_imgs=deploy/drink_dataset_v2.0/test_images/001.jpeg
# 输出
[{'bbox': [0, 0, 600, 600], 'rec_docs': '红牛-强化型', 'rec_scores': 0.74081033}]

# 预测文件夹内所有图片
python deploy/python/predict_system.py -c deploy/configs/inference_general.yaml -o Global.use_gpu=False -o Global.infer_imgs=deploy/drink_dataset_v2.0/test_images
# 输出
[{'bbox': [0, 0, 600, 600], 'rec_docs': '红牛-强化型', 'rec_scores': 0.74081033}]
Inference: 78.38726043701172 ms per batch image
[{'bbox': [0, 0, 514, 436], 'rec_docs': '康师傅矿物质水', 'rec_scores': 0.6918598}]
Inference: 72.65782356262207 ms per batch image
[{'bbox': [138, 40, 573, 1198], 'rec_docs': '乐虎功能饮料', 'rec_scores': 0.6821406}]
Inference: 72.5698471069336 ms per batch image
[{'bbox': [328, 7, 467, 272], 'rec_docs': '脉动', 'rec_scores': 0.6040604}]
Inference: 79.4534683227539 ms per batch image
[{'bbox': [242, 82, 498, 726], 'rec_docs': '味全_每日C', 'rec_scores': 0.54286546}]
Inference: 73.96435737609863 ms per batch image
[{'bbox': [437, 71, 660, 728], 'rec_docs': '元气森林', 'rec_scores': 0.77402496}, {'bbox': [221, 72, 449, 701], 'rec_docs': '元气森林', 'rec_scores': 0.6950992}, {'bbox': [794, 104, 979, 652], 'rec_docs': '元气森林', 'rec_scores': 0.6305152}]
Inference: 78.69076728820801 ms per batch image
[{'bbox': [0, 0, 768, 1024], 'rec_docs': '脉动', 'rec_scores': 0.5190187}]
Inference: 79.32877540588379 ms per batch image
[{'bbox': [233, 57, 525, 1038], 'rec_docs': '康师傅冰红茶', 'rec_scores': 0.6001749}]
Inference: 76.13968849182129 ms per batch image
[{'bbox': [493, 13, 803, 829], 'rec_docs': '康师傅冰红茶', 'rec_scores': 0.70879036}, {'bbox': [189, 17, 495, 793], 'rec_docs': '康师傅冰红茶', 'rec_scores': 0.69420344}]
Inference: 71.82860374450684 ms per batch image
[]
Inference: 91.88318252563477 ms per batch image
[]
Inference: 75.86908340454102 ms per batch image
[{'bbox': [0, 0, 730, 1095], 'rec_docs': '农夫山泉-饮用天然水', 'rec_scores': 0.68553746}]
Inference: 74.47957992553711 ms per batch image
</code></pre>
<h2 id="44-主体检测模块">4.4 主体检测模块</h2>
<pre><code class="language-python"># 预测单张图片
python deploy/python/predict_det.py -c deploy/configs/inference_general.yaml -o Global.use_gpu=False -o Global.infer_imgs=deploy/drink_dataset_v2.0/test_images/002.jpeg
# 输出
[{'class_id': 0, 'score': 0.8008015, 'bbox': array([2.3382977e+02, 1.4137268e-02, 3.7298141e+02, 4.3600000e+02],
      dtype=float32), 'label_name': 'foreground'}, {'class_id': 0, 'score': 0.42941576, 'bbox': array([  0.     , 272.02524, 514.     , 435.15088], dtype=float32), 'label_name': 'foreground'}, {'class_id': 0, 'score': 0.26006204, 'bbox': array([229.9466 , 266.22577, 379.64105, 435.57114], dtype=float32), 'label_name': 'foreground'}, {'class_id': 0, 'score': 0.21821804, 'bbox': array([234.0829 , 279.89706, 514.     , 435.49277], dtype=float32), 'label_name': 'foreground'}, {'class_id': 0, 'score': 0.21736334, 'bbox': array([  0.       ,   3.8394742, 472.9032   , 435.02594  ], dtype=float32), 'label_name': 'foreground'}]
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PaddleDetection测试脚本记录]]></title>
        <id>https://lichuanqi.github.io/paddledetection-ce-shi-jiao-ben-ji-lu/</id>
        <link href="https://lichuanqi.github.io/paddledetection-ce-shi-jiao-ben-ji-lu/">
        </link>
        <updated>2022-10-15T10:38:09.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-吸烟检测测试-20221012">1 吸烟检测测试 20221012</h1>
<h2 id="11-pipline-行人检测吸烟检测">1.1 pipline 行人检测+吸烟检测</h2>
<pre><code class="language-bash">python deploy/pipeline/pipeline.py --config deploy\pipeline\config\examples\infer_cfg_smoking.yml --video_file D:\Data\Smoke\test2_video\video3-1.mp4
</code></pre>
<h2 id="12-行人检测模块静态图预测">1.2 行人检测模块静态图预测</h2>
<pre><code class="language-bash"># 单张图片
python deploy/python/infer.py --model_dir=models\mot_ppyoloe_l_36e_pipeline --image_file=demo/000000014439_640x640.jpg --device=cpu

# 单个视频
python deploy/python/infer.py --model_dir=models\mot_ppyoloe_l_36e_pipeline --video_file=D:/Data/Smoke/test2_video/video3-1.mp4 --device=cpu
# 图像中有人时的输出结果
detect frame: 357
Test iter 0
class_id:0, confidence:0.9342, left_top:[183.13,122.14],right_bottom:[247.16,245.90]
</code></pre>
<h2 id="13-吸烟检测静态图预测">1.3 吸烟检测静态图预测</h2>
<pre><code>python deploy/python/infer.py --model_dir models\ppyoloe_crn_s_80e_smoking_visdrone --image_file D:\Data\Smoke\test1\000067.jpg --device=cpu
</code></pre>
<h1 id="2-安全帽检测">2 安全帽检测</h1>
<p>数据在实验室GPU，待更新</p>
<h2 id="pipline-行人检测安全帽">pipline 行人检测+安全帽</h2>
<h2 id="安全帽检测模块">安全帽检测模块</h2>
<h3 id="数据准备">数据准备</h3>
<p>下载数据集后解压，文件夹按照以下结构重命名</p>
<pre><code>-- Helmet
  |-- Annotations
    |-- 001.jpg
    |-- ... 
  |-- JPEGImages
    |-- 001.xml
    |-- ... 
</code></pre>
<p>使用以下数据将数据划分为训练集、验证集、测试集</p>
<pre><code>paddlex --split_dataset --format VOC --dataset_dir datasets/Helmet --val_value 0.2 --test_value 0.1
</code></pre>
<p>完成后数据集文件结构如下</p>
<pre><code>-- Helmet
  |-- Annotations
    |-- 001.jpg
    |-- ... 
  |-- JPEGImages
    |-- 001.xml
    |-- ... 
  |-- train_list.txt
  |-- val_list.txt
  |-- test_list.txt
  |-- labels.txt
</code></pre>
<h3 id="训练">训练</h3>
<pre><code>python -m paddle.distributed.launch --gpus 0,1 tools/train.py -c configs/ppyoloe/ppyoloe_plus_crn_m_80e_Helmet.yml --use_vdl True --vdl_log_dir output/scalar --eval

# 可视化查看训练数据
visualdl --logdir output/scalar --host 0.0.0.0 --port 8041
</code></pre>
<h3 id="评估">评估</h3>
<pre><code class="language-python"># 评估验证集结果
CUDA_VISIBLE_DEVICES=0 python tools/eval.py -c configs/ppyoloe/ppyoloe_plus_crn_m_80e_Helmet.yml -o weights=output/ppyoloe_plus_crn_m_80e_Helmet/weights/best_model.pdparams
# 输出
[10/17 12:24:57] ppdet.engine INFO: Eval iter: 0
[10/17 12:25:09] ppdet.engine INFO: Eval iter: 100
[10/17 12:25:21] ppdet.engine INFO: Eval iter: 200
[10/17 12:25:33] ppdet.engine INFO: Eval iter: 300
[10/17 12:25:45] ppdet.engine INFO: Eval iter: 400
[10/17 12:25:57] ppdet.metrics.metrics INFO: Accumulating evaluatation results...
[10/17 12:25:57] ppdet.metrics.metrics INFO: mAP(0.50, 11point) = 61.77%
[10/17 12:25:57] ppdet.engine INFO: Total sample number: 1000, averge FPS: 16.343893553616113
</code></pre>
<h3 id="动态图预测">动态图预测</h3>
<pre><code># 预测单张图片
CUDA_VISIBLE_DEVICES=0 python tools/infer.py -c configs/ppyoloe/ppyoloe_plus_crn_m_80e_Helmet.yml -o weights=output/ppyoloe_plus_crn_m_80e_Helmet/weights/best_model.pdparams --infer_img=dataset/Helmet/JPEGImages/hard_hat_workers1783.png --output_dir output --visualize True
# 输出
fer_img=dataset/Helmet/JPEGImages/hard_hat_workers1783.png --output_dir output --visualize True
W1017 12:26:25.761562 788568 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.6, Runtime API Version: 10.2
W1017 12:26:25.769194 788568 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.
[10/17 12:26:28] ppdet.utils.checkpoint INFO: Finish loading model weights: output/ppyoloe_plus_crn_m_80e_Helmet/weights/best_model.pdparams
100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01&lt;00:00,  1.30s/it]
[10/17 12:26:29] ppdet.engine INFO: Detection bbox results save in output/hard_hat_workers1783.png
</code></pre>
<h3 id="导出">导出</h3>
<h3 id="静态图预测">静态图预测</h3>
<h1 id="3-ppyoloe_plus_crn_l_80e_coco-20221015">3 ppyoloe_plus_crn_l_80e_coco 20221015</h1>
<h2 id="31-动态图预测">3.1 动态图预测</h2>
<pre><code>python tools/infer.py -c configs/ppyoloe/ppyoloe_plus_crn_m_80e_coco.yml -o weights=models\ppyoloe\ppyoloe_plus_crn_m_80e_coco.pdparams use_gpu=false --infer_img=demo\hrnet_demo.jpg
</code></pre>
<h2 id="32-动态图导出静态图">3.2 动态图导出静态图</h2>
<pre><code>python tools/export_model.py -c configs/ppyoloe/ppyoloe_plus_crn_m_80e_coco.yml -o weights=models\ppyoloe\ppyoloe_plus_crn_m_80e_coco.pdparams use_gpu=false --output_dir models
</code></pre>
<h2 id="33-静态图预测">3.3 静态图预测</h2>
<p>python deploy/python/infer.py --model_dir=models/ppyoloe_plus_crn_m_80e_coco --image_file=demo/000000014439_640x640.jpg --device=cpu</p>
<h1 id="4-picodet主体检测-20221015">4 picodet主体检测 20221015</h1>
<h2 id="41-动态图预测">4.1 动态图预测</h2>
<pre><code>python tools/infer.py -c configs\picodet\application\mainbody_detection\picodet_lcnet_x2_5_640_mainbody.yml --infer_dir=demo --output_dir=output  -o weights=models\picodet\picodet_PPLCNet_x2_5_mainbody_lite_v1.0_pretrained.pdparams --save_results True
</code></pre>
<h2 id="42-动态图导出静态图">4.2 动态图导出静态图</h2>
<pre><code>python tools/export_model.py -c configs\picodet\application\mainbody_detection\picodet_lcnet_x2_5_640_mainbody.yml -o weights=models\picodet\picodet_PPLCNet_x2_5_mainbody_lite_v1.0_pretrained.pdparams --output_dir models
</code></pre>
<h2 id="43-静态图预测">4.3 静态图预测</h2>
<pre><code>python deploy/python/infer.py --model_dir=models\picodet_lcnet_x2_5_640_mainbody --image_file=D:\Data\Retail_Product_Identification\test_image\recognition_2.jpg --device=cpu --save_results True
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PaddleNLP快递单信息抽取]]></title>
        <id>https://lichuanqi.github.io/paddlenlp-kuai-di-dan-xin-xi-chou-qu/</id>
        <link href="https://lichuanqi.github.io/paddlenlp-kuai-di-dan-xin-xi-chou-qu/">
        </link>
        <updated>2022-10-15T02:42:03.000Z</updated>
        <content type="html"><![CDATA[<h1 id="任务目标">任务目标</h1>
<p>输入“张三18625584663广东省深圳市南山区学府路东百度国际大厦”，目标是识别出其中的“张三”为人名（用符号 P 表示），“18625584663”为电话名（用符号 T 表示），“广东省深圳市南山区百度国际大厦”分别是 1-4 级的地址（分别用 A1~A4 表示，可以释义为省、市、区、街道）。</p>
<p>这是一个典型的命名实体识别（Named Entity Recognition，NER）场景，各实体类型及相应符号表示见下表：</p>
<table>
<thead>
<tr>
<th style="text-align:center">抽取实体/字段</th>
<th style="text-align:center">符号</th>
<th style="text-align:center">抽取结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">姓名</td>
<td style="text-align:center">P</td>
<td style="text-align:center">张三</td>
</tr>
<tr>
<td style="text-align:center">电话</td>
<td style="text-align:center">T</td>
<td style="text-align:center">18625584663</td>
</tr>
<tr>
<td style="text-align:center">省</td>
<td style="text-align:center">A1</td>
<td style="text-align:center">广东省</td>
</tr>
<tr>
<td style="text-align:center">市</td>
<td style="text-align:center">A2</td>
<td style="text-align:center">深圳市</td>
</tr>
<tr>
<td style="text-align:center">区</td>
<td style="text-align:center">A3</td>
<td style="text-align:center">南山区</td>
</tr>
<tr>
<td style="text-align:center">详细地址</td>
<td style="text-align:center">A4</td>
<td style="text-align:center">百度国际大厦</td>
</tr>
</tbody>
</table>
<h1 id="依赖安装">依赖安装</h1>
<p>此处略过</p>
<h1 id="数据准备">数据准备</h1>
<h2 id="数据标注格式">数据标注格式</h2>
<h2 id="数据下载">数据下载</h2>
<p>下载waybill数据集：https://paddlenlp.bj.bcebos.com/paddlenlp/datasets/waybill.tar.gz<br>
。解压后文件结构如下</p>
<pre><code>--waybil
  |-- train.txt
  |-- dev.txt
  |-- test.txt
  |-- word.dic
  |-- tag.dic
</code></pre>
<h1 id="训练">训练</h1>
<pre><code>conda activate paddle
cd D:\Code\PADDLE\PaddleNLP-develop
python examples\information_extraction\waybill_ie\run_ernie.py --save_dir examples/information_extraction/waybill_ie/ernir_ckpt  --epochs 20 --batch_size 64 --device cpu --data_dir D:\Data\waybill
</code></pre>
<h1 id="模型导出">模型导出</h1>
<pre><code>python examples\information_extraction\waybill_ie\export_model.py --params_path examples\information_extraction\waybill_ie\ernir_ckpt\model_100\model_state.pdparams --output_path examples/information_extraction/waybill_ie/ernir_inference --data_dir D:\Data\waybill
</code></pre>
<h1 id="使用导出的模型预测">使用导出的模型预测</h1>
<pre><code class="language-python">python examples/information_extraction/waybill_ie/deploy/python/predict.py --model_dir examples\information_extraction\waybill_ie\ernir_inference\ --data_dir D:\Data\waybill

# 输出
('黑龙江省', 'A1')('双鸭山市', 'A2')('尖山区', 'A3')('八马路与东平行路交叉口北40米', 'A4')('韦业涛', 'P')('18600009172', 'T')
('广西壮族自治区', 'A1')('桂林市', 'A2')('雁山区', 'A3')('雁山镇西龙村老年活动中心', 'A4')('17610348888', 'T')('羊卓卫', 'P')
('15652864561', 'T')('河南省', 'A1')('开封市', 'A2')('顺河回族区', 'A3')('顺河区公园路32号', 'A4')('赵本山', 'P')
('河北省', 'A1')('唐山市', 'A2')('玉田县', 'A3')('无终大街159号', 'A4')('18614253058', 'T')('尚汉生', 'P')
('台湾', 'A1')('台中市', 'A2')('北区', 'A3')('北区锦新街18号', 'A4')('18511226708', 'T')('蓟丽', 'P')
('廖梓琪', 'P')('18514743222', 'T')('湖北省', 'A1')('宜昌市', 'A2')('长阳土家族自治县', 'A3')('贺家坪镇贺家坪村一组临河1号', 'A4')
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用kenLM训练语言模型]]></title>
        <id>https://lichuanqi.github.io/shi-yong-kenlm-xun-lian-yu-yan-mo-xing/</id>
        <link href="https://lichuanqi.github.io/shi-yong-kenlm-xun-lian-yu-yan-mo-xing/">
        </link>
        <updated>2022-10-09T14:48:40.000Z</updated>
        <content type="html"><![CDATA[<p>最近在做语音识别相关的内容，发现错误主要出现在专有名词上，在查资料过程中发现可以用专业词训练一个语言模型（Language Model, LM）。</p>
<p>方法有：N-gram LM、FeedForward Neural Network LM、RNN LM和GPT系列，具体可以看 <a href="https://zhuanlan.zhihu.com/p/32292060">https://zhuanlan.zhihu.com/p/32292060</a>。语言模型训练工具有：KenLM、Srilm。</p>
<p>这里主要使用KenLM训练N-gram LM用于deepspeech2的语音识别，环境为Ubuntu20.04。</p>
<h1 id="kenlm安装">kenlm安装</h1>
<p>依赖安装</p>
<pre><code>sudo apt-get install build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev
</code></pre>
<p>kenlm安装</p>
<pre><code>wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz
mkdir kenlm/build
cd kenlm/build
cmake ..
make -j2
</code></pre>
<h1 id="kenlm训练">kenlm训练</h1>
<p>kenlm训练使用C++，内部给了易于调用的接口，具体命令如下：</p>
<pre><code>kenlm/build/bin/lmplz -o 4 --prune 0 4 4 4 -S 80% --text PaddleSpeech/demos/language_model/address_corpus_chars.txt --arpa PaddleSpeech/demos/language_model/address_corpus_chars.arpa --discount_fallback
</code></pre>
<ul>
<li>-o 指定gram层数，这里是4-gram</li>
<li>--prune 指定剪枝参数：这里的0 4 4 4表示2-gram,3-gram,* 4-gram中频率小于4的都剪枝掉，这里的几个参数必须为非递减，第一个必须为0</li>
<li>-S 限制该程序使用的最大内存，若不设置容易内存溢出，设置了也不会明显降低训练速度</li>
<li>--text 训练语料，这里需要将语料处理为(今 天 天 气 不 错)或(今天 天气 不错)</li>
<li>-arpa 生成的模型字典文件</li>
<li>--discount_fallback 不指定会报以下的错误</li>
</ul>
<pre><code>ERROR: 4-gram discount out of range for adjusted count 2: -5.980026.  This means modified Kneser-Ney smoothing thinks something is weird about your data.  To override this error for e.g. a class-based model, rerun with --discount_fallback
</code></pre>
<p>训练完成后的输出如下</p>
<pre><code>=== 1/5 Counting and sorting n-grams ===
Reading /home/xxtc/lichuan/CODE/PaddleSpeech/demos/language_model/address_corpus_chars.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 63667 types 1504
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:18048 2:9124712448 3:17108837376 4:27374139392
Substituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5
Statistics:
1 1504 D1=0.548324 D2=1.11646 D3+=1.43081
2 1460/11077 D1=0.841168 D2=1.21918 D3+=1.35424
3 1564/16532 D1=0.908341 D2=0.836226 D3+=1.79261
4 1508/20400 D1=0.5 D2=1 D3+=1.5
Memory estimate for binary LM:
type     kB
probing 135 assuming -p 1.5
probing 159 assuming -r models -p 1.5
trie     74 without quantization
trie     57 assuming -q 8 -b 8 quantization
trie     73 assuming -a 22 array pointer compression
trie     56 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:18048 2:23360 3:31280 4:36192
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
*******#############################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:18048 2:23360 3:31280 4:36192
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
####################################################################################################
=== 5/5 Writing ARPA model ===
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Name:lmplz      VmPeak:52507348 kB      VmRSS:6648 kB   RSSMax:10477732 kB      user:2.8795     sys:8.74262     CPU:11.6222     real:11.5914
</code></pre>
<p>生成的模型字典文件ngram.arpa格式如下</p>
<pre><code>\data\
ngram 1=1504
ngram 2=1460
ngram 3=1564
ngram 4=1508

\1-grams:
-4.0209603	&lt;unk&gt;	0
0	&lt;s&gt;	-0.9991864
-1.9057258	&lt;/s&gt;	0
-1.8332356	中	-0.29883626
-2.137954	国	-0.17699695
-1.6351237	科	-0.6701027

\2-grams:
-1.8534635	科 &lt;/s&gt;	0
-1.4849854	公 &lt;/s&gt;	0
-1.9052719	司 &lt;/s&gt;	0
-1.8912891	京 &lt;/s&gt;	0
-1.0746682	招 &lt;/s&gt;	0

\3-grams:
-0.99153876	公 司 &lt;/s&gt;	0
-1.8763832	北 京 &lt;/s&gt;	0
-0.20964877	高 招 &lt;/s&gt;	0
-0.24112433	中 心 &lt;/s&gt;	0

\4-grams:
-0.15717009	限 公 司 &lt;/s&gt;
-0.46751702	团 公 司 &lt;/s&gt;
-0.14627926	分 公 司 &lt;/s&gt;
-0.25886127	支 公 司 &lt;/s&gt;
-0.07823124	任 公 司 &lt;/s&gt;
-0.41149858	总 公 司 &lt;/s&gt;
-0.08007565	易 公 司 &lt;/s&gt;

\end\
</code></pre>
<h1 id="生成词料库">生成词料库</h1>
<p>kenlm训练语言模型需要的输入主要为词料库 text，按照词料库的细粒度又可以分为词颗粒度和字颗粒度，文件每一行的内容如下所示。这里用用的是字颗粒度。</p>
<pre><code>原始数据
今天天气不错
而对楼市成交抑制作用最大的限购

词颗粒度
今天 天气 不错
而 对 楼市 成交 抑制 作用 最 大 的 限 购

字颗粒度
今 天 天 气 不 错
而 对 楼 市 成 交 抑 制 作 用 最 大 的 限 购
</code></pre>
<h1 id="arpa文件学习">arpa文件学习</h1>
<p>低阶数据部分（3-grams为最高阶的情况下，1-grams与2-grams即为低阶数据部分）每行有三个元素，左边的是该短语出现的概率，右边为该短语的 backoff 概率（衡量的是某个词后面能接不同词的能力），中间则为短语（即一元短语或二元短语）；<br>
高阶数据部分每行只有两个元素，缺少一个 backoff 概率。<br>
文件中记录的概率都是实际概率的常用对数值（10为底）</p>
<p>以最高阶为3-grams的短语(wd1,wd2,wd3)概率计算为例,如果3-grams数据部分出现了(wd1,wd2,wd3)，则直接使用它的概率即可；如果数据中没有出现过(wd1,wd2,wd3)这个短语的话，但是找到了(wd1,wd2)这个短语，以(wd1,wd2)的 backoff 概率乘以短语(wd2,wd3)的概率即可；若都找不到就以的(wd2,wd3)概率作为(wd1,wd2,wd3)的概率处理。</p>
<p>至于降到2-grams的情况后，仍然类比3-grams的情况，如果找不到该二元短语，就用第一个单词的 backoff 概率和第二个单词的概率相乘即可。</p>
<pre><code>p(wd3|wd1,wd2)= if(trigram exists)           p_3(wd1,wd2,wd3)
                else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2)
                else                         p(wd3|w2)

p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2)
            else              bo_wt_1(wd1)*p_1(wd2)
</code></pre>
<h1 id="模型量化">模型量化</h1>
<p>一般训练的模型比较大，为了便于使用，kenlm提供了模型量化的接口，具体如下：</p>
<pre><code># 查看量化参数
kenlm/build/bin/build_binary -s PaddleSpeech/demos/language_model/address_corpus_chars.arpa

# 输出的量化参数如下
Memory estimate for binary LM:
type     kB
probing 135 assuming -p 1.5
probing 159 assuming -r models -p 1.5
trie     74 without quantization
trie     57 assuming -q 8 -b 8 quantization
trie     73 assuming -a 22 array pointer compression
trie     56 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
</code></pre>
<p>根据上述结果选择合适参数量化</p>
<pre><code># 参数量化
kenlm/build/bin/build_binary -s PaddleSpeech/demos/language_model/address_corpus_chars.arpa PaddleSpeech/demos/language_model/address_corpus_chars.klm

# 输出结果
Reading PaddleSpeech/demos/language_model/address_corpus_chars.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
SUCCESS
</code></pre>
<h1 id="python调用">python调用</h1>
<pre><code># 安装python 包
pip install pypi-kenlm

# 设置模型路径导入模型
import kenlm
import numpy as

model=kenlm.Model(&quot;ngram.pt&quot;)

# model.score() 对句子进行打分
# bos=True, eos=True 给句子开头和结尾加上标记符
# 返回输入字符串的 log10 概率，得分越高，句子的组合方式越好
score = model.score('今 天 天 气 不 错',bos = True,eos = True)
print(score)

# model.full_scores()
# score是full_scores是精简版
# full_scores会返回： (prob, ngram length, oov) 包括：概率，ngram长度，是否为oov

# model.perplexity() 计算句子的困惑度。
perplexity =model.perplexity('今 天 天 气 不 错')
print(perplexity)

# model.full_scores() 计算句子的困惑度
s = '今 天 天 气 不 错'
prob = np.prod([math.pow(10.0, score) for score, _, _ in model.full_scores(s)])
n = len(list(m.full_scores(s)))
perplexity = math.pow(prob, 1.0/n)
print(perplexity)
</code></pre>
<h1 id="asr结果">asr结果</h1>
<p>10条音频的平均字错率从9.5%降到了2.1%</p>
<p>zh_giga.no_cna_cmn.prune01244.klm预测结果</p>
<pre><code>tts_0_0.wav	中国科技出版传媒股份有限公司	中国科技出版传媒股份有限公司	0.0
tts_1_0.wav	中国石化国际事业有限公司北京招标中心	中国石化国际事业有限公司北京招标中心	0.0
tts_2_8.wav	泽国蒋欢飞中国小年度快递包裹	祖国讲话非中国少年都快递包裹	0.42857142857142855
tts_3_10.wav	加多宝中国饮料有限公司	加多宝中国饮料有限公司	0.0
tts_4_9.wav	中国长城科技集团股份有限公司	中国长城科技集团股份有限公司	0.0
tts_5_6.wav	诺维信中国投资有限公司	莫为信中国投资有限公司	0.18181818181818182
tts_6_3.wav	中国人寿保险股份有限公司北京市分公司	中国人受保险股份有限公司北京市分公司	0.05555555555555555
tts_7_2.wav	中国人民财产保险股份有限公司北京市大兴支公司	中国人民财产保险股份有限公司北京市大兴职公司	0.045454545454545456
tts_8_5.wav	淡水河谷矿产品中国有限公司	但水和古矿产品中国有限公司	0.23076923076923078
tts_9_6.wav	中国民生信托有限公司	中国民生信托有限公司	0.0
</code></pre>
<p>address_corpus_chars_n5.klm预测结果</p>
<pre><code>tts_0_0.wav	中国科技出版传媒股份有限公司	中国科技出版传媒股份有限公司	0.0
tts_1_0.wav	中国石化国际事业有限公司北京招标中心	中国石化国际事业有限公司北京招标中心	0.0
tts_2_8.wav	泽国蒋欢飞中国小年度快递包裹	泽国蒋欢飞中国小年度快递包裹	0.0
tts_3_10.wav	加多宝中国饮料有限公司	加多宝中国饮料有限公司	0.0
tts_4_9.wav	中国长城科技集团股份有限公司	中国长城科技集团股份有限公司	0.0
tts_5_6.wav	诺维信中国投资有限公司	诺维信中国投资有限公司	0.0
tts_6_3.wav	中国人寿保险股份有限公司北京市分公司	中国人手保险股份有限公司北京市分公司	0.05555555555555555
tts_7_2.wav	中国人民财产保险股份有限公司北京市大兴支公司	中国人民财产保险股份有限公司北京市大兴支公司	0.0
tts_8_5.wav	淡水河谷矿产品中国有限公司	但水和谷矿产品中国有限公司	0.15384615384615385
tts_9_6.wav	中国民生信托有限公司	中国民生信托有限公司	0.0
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ubuntu20.04安装Nvidia驱动、Cuda10.2、Cudnn8.5]]></title>
        <id>https://lichuanqi.github.io/ubuntu2004-an-zhuang-nvidia-qu-dong-cuda102cudnn85/</id>
        <link href="https://lichuanqi.github.io/ubuntu2004-an-zhuang-nvidia-qu-dong-cuda102cudnn85/">
        </link>
        <updated>2022-09-22T08:06:14.000Z</updated>
        <content type="html"><![CDATA[<h1 id="安装nvidia-510驱动">安装Nvidia-510驱动</h1>
<p>目前用的是apt install的方式安装，使用中没有发现什么问题。</p>
<h1 id="安装cuda102">安装cuda10.2</h1>
<h2 id="1-下载">1 下载</h2>
<p>我这里用的ubuntu20.04，由于没有指定版本，下载的18.04的版本</p>
<p>cuda下载链接：<br>
https://developer.nvidia.com/cuda-downloads<br>
cuda历史版本下载链接：<br>
https://developer.nvidia.com/cuda-toolkit-archive<br>
(或点击 ‘Archive of Previous CUDA Releases’进入下载页面)</p>
<h2 id="2-安装">2 安装</h2>
<p>有的博主说需要关闭图形界面，但我是直接在文件所在目录的终端里安装成功的</p>
<pre><code># Ctrl+Alt+F1 退出图形界面
sudo service lightdm stop

sudo sh ./cuda_10.2.89_440.33.01_linux.run
如果提示gcc版本问题:
Failed to verify gcc version.
See log at /var/log/cuda-installer.log for details.
解决方式1：cat /var/log/cuda-installer.log 则会看到问题及解决方法，执行时加上 --override 来忽略gcc版本不匹配问题。

sudo sh cuda_10.2.89_440.33.01_linux.run --override
</code></pre>
<h2 id="3-配置cuda环境变量">3 配置cuda环境变量</h2>
<pre><code>gedit ~/.bashrc
# 在末尾加上以下内容：
export PATH=/usr/local/cuda-10.2/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH
</code></pre>
<h2 id="4-保存退出后使环境变量生效">4 保存退出后使环境变量生效：</h2>
<pre><code>source ~/.bashrc
</code></pre>
<h2 id="查看cuda版本信息">查看cuda版本信息</h2>
<pre><code>nvcc -V
</code></pre>
<h1 id="安装cudnn85">安装cuDNN8.5</h1>
<h2 id="1-下载-2">1 下载</h2>
<p>下载链接：<br>
https://developer.nvidia.com/rdp/cudnn-download</p>
<p>下载 cuda10.2 对应的版本，解压，进入解压后的文件夹打开终端</p>
<h2 id="2-解压">2 解压</h2>
<pre><code>tar -xzvf {cudnn文件名}.tgz
</code></pre>
<h2 id="3-复制文件">3 复制文件</h2>
<pre><code>cd cudnn-linux-x86_64-8.5.0.96_cuda10-archive
sudo cp include/cudnn*.h /usr/local/cuda/include
sudo cp -P lib/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
</code></pre>
<h2 id="4-查看cudnn版本信息">4 查看cudnn版本信息</h2>
<pre><code>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[未报价顺丰快递丢失，赔偿沟通记录。]]></title>
        <id>https://lichuanqi.github.io/wei-bao-jie-shun-feng-kuai-di-diu-shi-pei-chang-gou-tong-ji-lu/</id>
        <link href="https://lichuanqi.github.io/wei-bao-jie-shun-feng-kuai-di-diu-shi-pei-chang-gou-tong-ji-lu/">
        </link>
        <updated>2022-04-12T06:02:58.000Z</updated>
        <content type="html"><![CDATA[<h2 id="背景">背景</h2>
<p>2022年4月1日（星期五），托朋友帮忙购买了12个冰墩墩钥匙扣和8个雪融融钥匙扣，并通过顺丰快递邮寄给我，发货地和收货地均为北京，付款方式为到付。晚上通过顺丰官网的快递查询到，下午17：32已经被快递员揽收（单号：SF1413968843540），23：31由北京顺航中转场发出。虽然为同城快递，但是考虑到正处于清明假期期间，一直在等待快递信息的更新。</p>
<h2 id="沟通记录">沟通记录</h2>
<p>4月3日上午9：47，经过咨询顺丰官方客服电话（95338），答复是48小时内如果找不到就认定为快递丢失，并且登记了商品的价值1360和索赔金额2000。但是48小时后顺丰并没有主动联系我。</p>
<p>4月6日上午10：00左右，再次拨通顺丰官方客服电话，答复是开始走索赔流程，再次确认了商品的价值1360元和索赔金额2000元。</p>
<p>4月7日，收到顺丰索赔经理的电话，需要提供商品价值的证明，本人按照要求提供了购买小票照片、微信转账截图和快递揽收前的商品照片。可以证明钥匙扣的单价为68元、总价为1360元。</p>
<p>4月8日，经过主动咨询顺丰官方客服电话（95338），从客服得到的赔偿方案：由于商品没有报价，只能赔偿运费的7倍即98元。本人答复是：对目前的赔偿非常不满意，要求按照之前登记的索赔金额2000赔偿。客服的回答：需要和公司反馈，后续有消息再联系。</p>
<p>4月9日，再次拨通顺丰官方客服电话，客服答复：当天处于非工作日，需要下周一才能给我确定的答复，但是</p>
<p>4月11日，截止到下午15：00还没有收到答复电话，已经在国家邮政局投诉网站登记投诉。</p>
<p>4月12日下午13：38，收到顺丰索赔经理的电话，目前的赔偿方案是原价值的50%即680元，我的回答是完全不能接受。猜测是在邮政局的投诉顺丰还没有开始处理，等一波消息。</p>
<p>丢件实践最终以快递员全额赔偿大结局。</p>
<h2 id="总结">总结</h2>
<p>由于快递没有报价，所以沟通起来比较被动，但是还是有切入点的。后续贵重物品发快递一定报价。<br>
1、由于本人还是学生，没有经济收入，商品的丢失对我造成了重大的经济损失。<br>
2、钥匙扣购买时是按照人头对应购买的，快递丢失本人无法和其他人解释，对本人的口碑和信用造成了极坏的影响。<br>
3、快递的收费方式为到付，快递员揽收时并没有向我询问商品是否保价。<br>
4、顺丰官方客服两次询问并登记了商品的价值1360和索赔金额2000，均没有提出异议，本人认为已经默许同意次赔偿方案。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[deepin安装miniconda管理python环境]]></title>
        <id>https://lichuanqi.github.io/deepin-an-zhuang-miniconda-guan-li-python-huan-jing/</id>
        <link href="https://lichuanqi.github.io/deepin-an-zhuang-miniconda-guan-li-python-huan-jing/">
        </link>
        <updated>2022-04-10T03:10:41.000Z</updated>
        <content type="html"><![CDATA[<h1 id="背景">背景</h1>
<p>之前一直用anaconda，偶然发现实在是太占用空间了，我只有2个环境，足足占用了7G多的空间，趁着今天手误一不小心升级了一下python版本，导致环境直接崩溃，彻底的把 anaconda 更换为 miniconda，默认的环境1000多个库也没用过，要他有何用。</p>
<h1 id="更换步骤">更换步骤</h1>
<h2 id="1-删除anaconda">1、删除anaconda</h2>
<p>首先彻底删除之前安装的anaconda文件和配置信息，先删除主目录下的 ～/anaconda3 文件夹，可以手动删除，也可以使用以下代码在终端删除，亲测终端删除速度稍微快一点</p>
<pre><code># 删除anaconda文件
rm -rf ~/anaconda3
</code></pre>
<p>删除系统和用户配置信息中关于conda的代码，手动打开主目录下的 ~/.bashrc 文件删除conda的配置信息，如果没有就按 Ctrl+H 显示隐藏文件和文件夹，也可以在终端中使用vim删除。</p>
<pre><code># vim打开 ~/.bashrc
sudo vim ~/.bashrc
# 删除conda相关的代码，类似下面这样的
# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;
# !! Contents within this block are managed by 'conda init' !!
__conda_setup=&quot;$('/home/lc/anaconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)&quot;
if [ $? -eq 0 ]; then
    eval &quot;$__conda_setup&quot;
else
    if [ -f &quot;/home/lc/anaconda3/etc/profile.d/conda.sh&quot; ]; then
        . &quot;/home/lc/anaconda3/etc/profile.d/conda.sh&quot;
    else
        export PATH=&quot;/home/lc/anaconda3/bin:$PATH&quot;
    fi
fi
unset __conda_setup
# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;
# vim打开 /etc/profile
sudo vim /etc/profile
# 删除conda相关的代码
</code></pre>
<h2 id="2-下载miniconda">2、下载miniconda</h2>
<p>可以手动从以下镜像下载，也可以使用 wget 在终端中下载，我这里下载的是最新的 Miniconda-latest-Linux-x86_64.sh</p>
<ul>
<li>官方镜像https://docs.conda.io/en/latest/miniconda.html</li>
<li>Miniconda3-latest-Linux-x86_64.shhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</li>
<li>清华镜像https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/</li>
<li>Miniconda3-latest-Linux-x86_64.shhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh</li>
</ul>
<h2 id="3-安装miniconda">3、安装miniconda</h2>
<p>打开深度终端，切换到刚才的下载目录，执行以下代码</p>
<pre><code># 安装
bash Miniconda-latest-Linux-x86_64.sh
# 开始疯狂的enter/backspace/yes
# 输入yes接受条约
Do you accept the license terms? [yes|no]
# enter，安装到默认的主目录下
[/home/lc/miniconda3] &gt;&gt;&gt; 
# 输入yes，自动配置环境变量
installation finished.
Do you wish the installer to initialize Miniconda2
in your /home/you/.bashrc ? [yes|no]
# 出现这个代表安装成功
Thank you for installing Miniconda2!
# 更新系统配置信息
source ~/.bashrc
# 输入以下代码，出现conda的帮助文档信息，即表明conda安装成功
conda --help
conda子命令的帮助文档
conda create --help
</code></pre>
<h2 id="4-更改镜像源">4、更改镜像源</h2>
<p>终端依次执行以下代码，将下载的镜像源改为清华的镜像</p>
<pre><code>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda
conda config --set show_channel_urls yes
</code></pre>
<h1 id="开始使用">开始使用</h1>
<p>和anaconda命令一样，为了加快pip安装速度，将其镜像源改为清华，请参考《使用pypi国内镜像资源站解决Python工具包安装失败》http://www.dlc618.com/post-881.html</p>
<pre><code># 创建虚拟环境
conda create -n test python=3.6
# 进入虚拟环境
conda activate test
# pip镜像改为清华
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
# pip安装库
pip install opencv-python==3.4.3.18
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Markdown笔记]]></title>
        <id>https://lichuanqi.github.io/markdown-bi-ji/</id>
        <link href="https://lichuanqi.github.io/markdown-bi-ji/">
        </link>
        <updated>2022-04-07T09:07:18.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一级标题">一级标题</h1>
<pre><code># 一级标题
</code></pre>
<h2 id="二级标题">二级标题</h2>
<pre><code># 二级标题
</code></pre>
<p>正文</p>
<pre><code>正文
</code></pre>
<h3 id="无序列表">无序列表</h3>
<pre><code>* a
* b
* c
</code></pre>
<ul>
<li>a</li>
<li>b</li>
<li>c</li>
</ul>
<h3 id="有序列表">有序列表</h3>
<pre><code>1. a
2. b
3. c
</code></pre>
<ol>
<li>a</li>
<li>b</li>
<li>c</li>
</ol>
<h3 id="任务列表">任务列表</h3>
<pre><code>- [ ] 表示该项目未完成；
- [x] 表示该项目已完成
</code></pre>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox" id="task-item-9013744"><label class="task-list-item-label" for="task-item-9013744"> 表示该项目未完成；</label></li>
<li class="task-list-item"><input class="task-list-item-checkbox" checked="" disabled="" type="checkbox" id="task-item-3265907"><label class="task-list-item-label" for="task-item-3265907"> 表示该项目已完成</label></li>
</ul>
<h3 id="引用">引用</h3>
<pre><code>&gt; 这是一个引用
</code></pre>
<blockquote>
<p>这是一个引用</p>
</blockquote>
<h3 id="图片">图片</h3>
<pre><code>![Alt text](/logo.png 'logo')
</code></pre>
<h3 id="超链接">超链接</h3>
<pre><code>欢迎访问博客 [一艘大轮船](http://www.dlc618.com &quot;一艘大轮船&quot;)
</code></pre>
<p>欢迎访问博客 <a href="http://www.dlc618.com" title="一艘大轮船">一艘大轮船</a></p>
<h2 id="正文中的一些格式">正文中的一些格式</h2>
<pre><code>*斜体*
**粗体**
***加粗斜体***
~~删除线~~
++下划线++
==背景高亮==
</code></pre>
<p><em>斜体</em></p>
<p><strong>粗体</strong></p>
<p><em><strong>加粗斜体</strong></em></p>
<p><s>删除线</s></p>
<p>++下划线++</p>
<p><mark>背景高亮</mark></p>
<h2 id="参考">参考</h2>
<pre><code>我经常去的几个网站[Google][1]、[Leanote][2]

[1]:http://www.google.com 
[2]:http://www.leanote.com
</code></pre>
<p>我经常去的几个网站<a href="http://www.google.com">Google</a>、<a href="http://www.leanote.com">Leanote</a></p>
<h1 id="块语法">块语法</h1>
<h2 id="代码块">代码块:</h2>
<pre><code class="language-python">print('Hello’)
if a==1：
    b = a
else:
    a =  a * a  
</code></pre>
<h2 id="行内代码">行内代码：</h2>
<pre><code>正文`print('Hello')`正文
</code></pre>
<p>正文<code>print('Hello')</code>正文</p>
<h2 id="表格">表格</h2>
<pre><code>|学号|姓名|序号|
| - | - | - |
|小明明|男|5  |
|小红   |女|79|
|小陆   |男|19|
</code></pre>
<table>
<thead>
<tr>
<th>学号</th>
<th>姓名</th>
<th>序号</th>
</tr>
</thead>
<tbody>
<tr>
<td>小明明</td>
<td>男</td>
<td>5</td>
</tr>
<tr>
<td>小红</td>
<td>女</td>
<td>79</td>
</tr>
<tr>
<td>小陆</td>
<td>男</td>
<td>192</td>
</tr>
</tbody>
</table>
<h3 id="分割线">分割线</h3>
<pre><code>***
---
</code></pre>
<hr>
<hr>
]]></content>
    </entry>
</feed>